%> ------------------------------------------------------------------------
%> ENGN2560: Computer Vision
%>    Lab04: Absolute Camera Pose and Visual Odometry
%> Problem3: Visual Odometry Part II
%> ------------------------------------------------------------------------
clc; clear all; close all;
rng(0);

%> Load camera intrinsic matrix (borrowed from Problem2)
load('data/Problem2/IntrinsicMatrix.mat');

%> Load ground truth poses (borrowed from Problem2)
load('data/Problem2/GT_Poses.mat');	%> GT_Poses

%> Read all images in the sequence.
%> Use imread(Image_Sequence(i).name); to read image i
mfiledir = fileparts(mfilename('fullpath'));
Image_Sequence = dir([mfiledir, '/data/Problem2/fr2_desk/*.png']);

%> Parameters passed to RANSAC
PARAMS.INLIER_THRESH                          = 2;      %> 2 pixels
PARAMS.RANSAC_ITERATIONS                      = 1500;   %> Total number of RANSAC iterations
PARAMS.NUM_OF_FRAMES_FROM_LAST_KF             = 20;
PARAMS.RATIO_OF_COVISIBLE_POINTS_FROM_LAST_KF = 0.5;

%> =================================================================
%> TODO: Implement a Visual Odometry Pipeline Reducing Motion Drift
%> =================================================================
nImgs = length(Image_Sequence);

Img1 = imread(Image_Sequence(1).name);
Img2 = imread(Image_Sequence(2).name);

% computing scale

Rgi = GT_Poses(:,1:3,2);
Tgi = GT_Poses(:,4,2);
cgi = -Rgi' * Tgi;

Rgim1 = GT_Poses(:,1:3,1);
Tgim1 = GT_Poses(:,4,1);
cgim1 = -Rgim1' * Tgim1;

s = norm(cgi - cgim1);

% code from part 1

estimatedPoses = zeros(3, 4, nImgs);
estimatedPoses(:,:,1) = [eye(3), zeros(3,1)];

[R, T, E, matched1, matched2, d2, inlierMatches12, inlierIdxs] = estimateRelativePose(PARAMS, Img1, Img2, K);

R1 = eye(3);
T1 = zeros(3,1);
R2 = R;
T2 = T;

estimatedPoses(:,:,2) = [R2, s*T2];

nPoints = size(inlierIdxs, 2);

pointsSymmedian = zeros(3, nPoints);

for i=1:nPoints
    gamma1 = K \ [matched1(:, i); 1];
    gamma2 = K \ [matched2(:, i); 1];
    
    worldPoint = symmedianTriangulation(gamma1, gamma2, R1, T1, R2, T2);
    pointsSymmedian(:, i) = worldPoint;
end

% rest of the images
prev_kf_img = Img2;

prev_kf_triangulated = pointsSymmedian;
prev_kf_points3D = [];
prev_kf_idx = 2;

prev_kf_d = d2;
prev_kf_inlier_matches = inlierMatches12;

kf_idxs = false(1, nImgs);
kf_idxs(1:2) = [true, true];

for i=3:nImgs
    disp(i);
    currImg = imread(Image_Sequence(i).name);
    
    % compute absolute camera pose
    img_bw = single(rgb2gray(currImg));

    [f3, d3] = vl_sift(img_bw);
    
    [matches23, scores] = vl_ubcmatch(prev_kf_d, d3); % TODO: DEBUG THIS PART
    
    [~, ~, uniqueIdxs] = unique(prev_kf_inlier_matches(2,:), 'stable'); % features that are inliers
w
    idxs_of_unique = true(1, size(uniqueIdxs,1));
    next = 1;
    for j=1:size(uniqueIdxs,1)
        if uniqueIdxs(j) ~= next
            idxs_of_unique(j) = false;
        else
            next = next + 1;
        end
    end

    matches12_unique = prev_kf_inlier_matches(2, idxs_of_unique);

    matches_from_12_in_23_that_are_inliers = intersect(matches12_unique, matches23(1,:));
    matches_from_23_that_are_in_12 = ismember(matches23(1,:), matches_from_12_in_23_that_are_inliers);
    
    inMatched2 = matches23(1, matches_from_23_that_are_in_12);
    inMatched3 = matches23(2, matches_from_23_that_are_in_12);
    
    indices_from_12_that_are_inliers_in_23 = ismember(matches12_unique, matches_from_12_in_23_that_are_inliers);
    matches_from_12_that_are_inliers_in_23 = matches12_unique(indices_from_12_that_are_inliers_in_23);
    
    [sortedMatches, sortedIndices] = sort(matches_from_12_that_are_inliers_in_23, 'ascend');

    points2D = f3(1:2, inMatched3);

    pointsTriangulated = prev_kf_triangulated(:, idxs_of_unique);
    points3D = pointsTriangulated(:, indices_from_12_that_are_inliers_in_23);
    points3D = points3D(:, sortedIndices);
    
    [AbsR, AbsT] = Ransac4AbsPose(PARAMS, points3D, points2D, K);

    estimatedPoses(:,:,i) = [AbsR, s*AbsT];
        
    Np = size(points3D, 2);
    Nf = size(matches23, 2);
    % Nq = Nf - Np;
    covisRatio = Np / Nf;

    disp(covisRatio);
    
    if ((i - prev_kf_idx) > PARAMS.NUM_OF_FRAMES_FROM_LAST_KF) || ...
        (covisRatio < PARAMS.RATIO_OF_COVISIBLE_POINTS_FROM_LAST_KF)

        disp("new keyframe");
        
        [R, T, E, matched1, matched2, descriptors, newMatches, inlierIdxs] = estimateRelativePose(PARAMS, prev_kf_img, currImg, K);

        R1 = eye(3);
        T1 = zeros(3,1);
        R2 = R;
        T2 = T;
        
        nPoints = size(inlierIdxs, 2);
        
        pointsSymmedian = zeros(3, nPoints);
        
        for j=1:nPoints
            gamma1 = K \ [matched1(:, j); 1];
            gamma2 = K \ [matched2(:, j); 1];
            
            worldPoint = symmedianTriangulation(gamma1, gamma2, R1, T1, R2, T2);
            pointsSymmedian(:, j) = worldPoint;
        end

        pointsSymmedianTransformed = estimatedPoses(:,1:3,prev_kf_idx)*pointsSymmedian + estimatedPoses(:,4,prev_kf_idx);

        prev_kf_triangulated = pointsSymmedianTransformed;
        prev_kf_points3D = points3D;

        prev_kf_inlier_matches = newMatches;
        prev_kf_d = descriptors;

        prev_kf_img = currImg;
        prev_kf_idx = i;
        
        kf_idxs(i) = true;
    end

    R_gt = GT_Poses(:, 1:3, i);
    T_gt = GT_Poses(:, 4, i);

    [deltaR, deltaT] = getRT_Error(AbsR, s*AbsT, R_gt, T_gt);
    disp(deltaR);
    disp(deltaT);
end

Visualize_Trajectory(GT_Poses, estimatedPoses, find(kf_idxs));

% compute RMSE for R and T
r_sum = 0;
t_sum = 0;
for i=1:nImgs
    R_gt = GT_Poses(:, 1:3, i);
    T_gt = GT_Poses(:, 4, i);
    
    R = estimatedPoses(:, 1:3, i);
    T = estimatedPoses(:, 4, i);
    
    [deltaR, deltaT] = getRT_Error(R, T, R_gt, T_gt);
    r_sum = r_sum + (deltaR^2);
    t_sum = t_sum + (deltaT^2);
end

rmse_R = sqrt(r_sum / nImgs);
rmse_T = sqrt(t_sum / nImgs);

disp(rmse_R);
disp(rmse_T);

% FUNCTIONS ---------------------------------------------------------------

function [deltaR, deltaT] = getRT_Error(R, T, Rg, Tg)
    deltaR = acos((trace(Rg' * R) - 1) / 2);

    if norm(Tg) ~= 0
        Tg = Tg / norm(Tg);
    end

    if norm(T) ~= 0
        T = T / norm(T);
    end
    
    deltaT = abs(dot(Tg, T) - 1);
end

function [AbsR, AbsT] = Ransac4AbsPose(PARAMS, Points3D, Points2D, K)
    maxInliers = 0;

    Points2DHomogenous = [Points2D; ones(1, size(Points2D, 2))];

    Points2D_meters = K \ Points2DHomogenous;
    
    Points3DHomogenous = [Points3D; ones(1, size(Points3D, 2))]; 
    
    for i=1:PARAMS.RANSAC_ITERATIONS
        sample_col_idxs = randperm(size(Points3D, 2), 3);
        sample2D = Points2D_meters(:, sample_col_idxs);
        sample3D = Points3D(:, sample_col_idxs);
                
        [Rs, Ts] = P3P_LambdaTwist(sample2D, sample3D);
        
        num_candidates = size(Ts, 2);
        for j=1:num_candidates
            R_test = Rs(:, :, j);
            T_test = Ts(:, j);
            RT_test = [R_test, T_test];
            % RT_test = [R_gt, T_gt];
       
            test_M = K * RT_test;
            reprojected = test_M * Points3DHomogenous;
            reprojected(1,:) = reprojected(1,:) ./ reprojected(3,:);
            reprojected(2,:) = reprojected(2,:) ./ reprojected(3,:);
            
            distances = sqrt(sum((reprojected(1:2,:) - Points2D).^2));
            % dist = sum(sqrt(sum((reprojected(1:2,:) - points2D').^2, 2)));
            inliers = distances < PARAMS.INLIER_THRESH;
            
            inlierCount = sum(inliers);
            
            if inlierCount > maxInliers
                maxInliers = inlierCount;  
                AbsR = R_test;
                AbsT = T_test;
            end
        end
    end
end

function worldPoint = symmedianTriangulation(gamma1, gamma2, R1, T1, R2, T2)
    c1 = -R1' * T1;
    gamma1NormSq = norm(gamma1) ^ 2;
    inner1 = eye(3) - ((R1' * gamma1 * (gamma1' * R1)) / gamma1NormSq);
    
    c2 = -R2' * T2;
    gamma2NormSq = norm(gamma2) ^ 2;
    inner2 = eye(3) - ((R2' * gamma2 * (gamma2' * R2)) / gamma2NormSq);
    
    worldPoint = (inner1 + inner2) \ ((inner1 * c1) + (inner2 * c2));    
end

function S = getSkewSymmetric(v)
    S = [0, -v(3), v(2);
     v(3), 0, -v(1);
     -v(2), v(1), 0];
end

function [R, T, E] = deriveTransformations(E_final, matched1, matched2, K)
    [U, ~, V] = svd(E_final);
    W = [0, -1, 0; 1, 0, 0; 0, 0, 1];
    R1 = U * W * transpose(V);
    R2 = U * transpose(W) * transpose(V);
    
    if (det(R1) < 0 || det(R2) < 0)
        [U, ~, V] = svd(-E_final);
        W = [0, -1, 0; 1, 0, 0; 0, 0, 1];
        R1 = U * W * transpose(V);
        R2 = U * transpose(W) * transpose(V);
    end

    T_plus = U(:, 3);
    T_minus = -U(:, 3);

    % disp(det(R1));
    % disp(det(R2));
    
    candidateRTs = {R1, T_plus, R2, T_plus, R1, T_minus, R2, T_minus};

    mostPos = 0;
    bestR = [];
    bestT = [];
    
    for i=1:2:length(candidateRTs)
        curr_R = candidateRTs{i};
        curr_T = candidateRTs{i+1};

        % disp(curr_R);
        % disp(curr_T);

        posCount = 0;
        for j=1:size(matched1, 2)
            feature_1_homogenous = K \ [matched1(:, j); 1];
            feature_2_homogenous = K \ [matched2(:, j); 1];

            Rg1 = curr_R * feature_1_homogenous;
            A = [-Rg1, feature_2_homogenous];

            res = pinv(A) * curr_T;
            rho1 = res(1);
            rho2 = res(2);

            if (rho1 > 0) && (rho2 > 0)
                posCount = posCount + 1;
            end
        end
        if posCount > mostPos
           mostPos = posCount;
           bestR = curr_R;
           bestT = curr_T;
        end
    end

    bestTx = getSkewSymmetric(bestT); % [0, -bestT(3), bestT(2); bestT(3), 0, -bestT(1); -bestT(2), bestT(1), 0];
    test_E = bestTx * bestR;

    R = bestR;
    T = bestT;
    E = test_E;
end

function [R, T, E, matched1, matched2, d2, top_n, inlierIdxs] = estimateRelativePose(PARAMS, Img1, Img2, K)
    
    % converting to black and white
    img1_bw = single(rgb2gray(Img1));
    img2_bw = single(rgb2gray(Img2));

    % using SFIT
    [f1,d1] = vl_sift(img1_bw);
    [f2,d2] = vl_sift(img2_bw);

    % Matching
    [matches, scores] = vl_ubcmatch(d1, d2);
    % disp(matches);

    % creating rank order list 
    [sortedScores, sortedIndices] = sort(scores, 'ascend');
    sortedMatches = matches(:, sortedIndices);
    n = floor(0.8 * size(sortedMatches, 2));
    top_n = sortedMatches(:, 1:n);
    
    matched1 = f1(1:2, top_n(1, :));
    matched2 = f2(1:2, top_n(2, :));

    [E_final, inlierIdxs] = Ransac4Essential(PARAMS, matched1, matched2, K);
    
    top_n = top_n(:, inlierIdxs);
    matched1 = matched1(:, inlierIdxs);
    matched2 = matched2(:, inlierIdxs);

    [R,T,E] = deriveTransformations(E_final, matched1, matched2, K);

end

% RANSAC ------------------------------------------------------------------

function [E, inlier_Idx] = Ransac4Essential(PARAMS, gamma1, gamma2, K)
    maxInliers = 0;
    
    gamma1_homogeneous = [gamma1; ones(1, size(gamma1, 2))];
    gamma2_homogeneous = [gamma2; ones(1, size(gamma2, 2))];

    gamma1ToMeters = K \ gamma1_homogeneous;
    gamma2ToMeters = K \ gamma2_homogeneous;
    
    for i=1:PARAMS.RANSAC_ITERATIONS
        sample_col_idxs = randperm(size(gamma1, 2), 5);
        samples = ones(5, 3, 2);
        samples(:, 1:2, 1) = gamma1ToMeters(1:2, sample_col_idxs)';
        samples(:, 1:2, 2) = gamma2ToMeters(1:2, sample_col_idxs)';
                
        essential_candidates = fivePointAlgorithmSelf(samples);
        
        for j=1:length(essential_candidates)

            essential_test = essential_candidates{j};
            F = transpose(inv(K)) * essential_test / K;

            epipolar_lines = F * gamma1_homogeneous;
            distances = abs(sum(epipolar_lines .* gamma2_homogeneous, 1)) ./ sqrt(sum(epipolar_lines(1:2, :).^2, 1));

            inliers = distances < PARAMS.INLIER_THRESH;
            
            inlierCount = sum(inliers);
            
            if inlierCount > maxInliers
                maxInliers = inlierCount;                
                inlier_Idx = find(inliers == 1);
                E = essential_test;
            end
        end
    end
end
